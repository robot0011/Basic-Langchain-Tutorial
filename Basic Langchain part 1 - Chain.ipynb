{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apa Itu Langchain ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tavily-python langchain-experimental chromadb pypdf langchainhub langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-1.59.7-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-google-genai\n",
      "  Downloading langchain_google_genai-2.0.8-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Using cached PyYAML-6.0.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.37-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.11.11-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.29 (from langchain)\n",
      "  Downloading langchain_core-0.3.29-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.2.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<3,>=1.26.2 (from langchain)\n",
      "  Using cached numpy-2.2.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.10.5-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Using cached jiter-0.8.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Using cached tiktoken-0.8.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting google-generativeai<0.9.0,>=0.8.0 (from langchain-google-genai)\n",
      "  Using cached google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached attrs-24.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.5.0-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.1.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached propcache-0.2.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.18.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.10 (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai)\n",
      "  Using cached google_ai_generativelanguage-0.6.10-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-api-core (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai)\n",
      "  Using cached google_api_core-2.24.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai)\n",
      "  Downloading google_api_python_client-2.158.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai)\n",
      "  Using cached google_auth-2.37.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting protobuf (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai)\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai)\n",
      "  Using cached proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.29->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.14-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.27.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Using cached charset_normalizer-3.4.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.1-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Using cached regex-2024.11.6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai)\n",
      "  Using cached googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai)\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai)\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai)\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai)\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai)\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai)\n",
      "  Downloading grpcio-1.69.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai)\n",
      "  Downloading grpcio_status-1.69.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai)\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.59.7-py3-none-any.whl (454 kB)\n",
      "Downloading langchain_openai-0.3.0-py3-none-any.whl (54 kB)\n",
      "Downloading langchain_google_genai-2.0.8-py3-none-any.whl (41 kB)\n",
      "Using cached aiohttp-3.11.11-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Using cached anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached google_generativeai-0.8.3-py3-none-any.whl (160 kB)\n",
      "Using cached google_ai_generativelanguage-0.6.10-py3-none-any.whl (760 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached jiter-0.8.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
      "Downloading langchain_core-0.3.29-py3-none-any.whl (411 kB)\n",
      "Downloading langchain_text_splitters-0.3.5-py3-none-any.whl (31 kB)\n",
      "Downloading langsmith-0.2.10-py3-none-any.whl (326 kB)\n",
      "Using cached numpy-2.2.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "Downloading pydantic-2.10.5-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached PyYAML-6.0.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading SQLAlchemy-2.0.37-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached tiktoken-0.8.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-24.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "Using cached frozenlist-1.5.0-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (267 kB)\n",
      "Using cached google_api_core-2.24.0-py3-none-any.whl (158 kB)\n",
      "Using cached google_auth-2.37.0-py2.py3-none-any.whl (209 kB)\n",
      "Downloading greenlet-3.1.1-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (615 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.6/615.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached multidict-6.1.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "Downloading orjson-3.10.14-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Using cached propcache-0.2.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (227 kB)\n",
      "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Using cached regex-2024.11.6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached yarl-1.18.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (339 kB)\n",
      "Downloading google_api_python_client-2.158.0-py2.py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Using cached googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio-1.69.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.69.0-py3-none-any.whl (14 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: filetype, urllib3, uritemplate, typing-extensions, tqdm, tenacity, sniffio, regex, PyYAML, pyparsing, pyasn1, protobuf, propcache, orjson, numpy, multidict, jsonpointer, jiter, idna, h11, grpcio, greenlet, frozenlist, distro, charset-normalizer, certifi, cachetools, attrs, annotated-types, aiohappyeyeballs, yarl, SQLAlchemy, rsa, requests, pydantic-core, pyasn1-modules, proto-plus, jsonpatch, httplib2, httpcore, googleapis-common-protos, anyio, aiosignal, tiktoken, requests-toolbelt, pydantic, httpx, grpcio-status, google-auth, aiohttp, openai, langsmith, google-auth-httplib2, google-api-core, langchain-core, google-api-python-client, langchain-text-splitters, langchain-openai, google-ai-generativelanguage, langchain, google-generativeai, langchain-google-genai\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.37 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.8.0 attrs-24.3.0 cachetools-5.5.0 certifi-2024.12.14 charset-normalizer-3.4.1 distro-1.9.0 filetype-1.2.0 frozenlist-1.5.0 google-ai-generativelanguage-0.6.10 google-api-core-2.24.0 google-api-python-client-2.158.0 google-auth-2.37.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.3 googleapis-common-protos-1.66.0 greenlet-3.1.1 grpcio-1.69.0 grpcio-status-1.69.0 h11-0.14.0 httpcore-1.0.7 httplib2-0.22.0 httpx-0.28.1 idna-3.10 jiter-0.8.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.14 langchain-core-0.3.29 langchain-google-genai-2.0.8 langchain-openai-0.3.0 langchain-text-splitters-0.3.5 langsmith-0.2.10 multidict-6.1.0 numpy-2.2.1 openai-1.59.7 orjson-3.10.14 propcache-0.2.1 proto-plus-1.25.0 protobuf-5.29.3 pyasn1-0.6.1 pyasn1-modules-0.4.1 pydantic-2.10.5 pydantic-core-2.27.2 pyparsing-3.2.1 regex-2024.11.6 requests-2.32.3 requests-toolbelt-1.0.0 rsa-4.9 sniffio-1.3.1 tenacity-9.0.0 tiktoken-0.8.0 tqdm-4.67.1 typing-extensions-4.12.2 uritemplate-4.1.1 urllib3-2.3.0 yarl-1.18.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain openai langchain-openai langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faqih/latihan_go/Basic-Langchain-Tutorial/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini-2024-07-18\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meaning of life is a question that has been pondered by philosophers, theologians, scientists, and individuals for centuries.  There isn't one definitive answer that satisfies everyone.  Instead, the meaning of life is often considered a personal and evolving concept.  Here are some perspectives:\n",
      "\n",
      "* **Nihilism:**  This philosophy argues that life is inherently meaningless.  There's no objective purpose or value.\n",
      "\n",
      "* **Existentialism:**  This perspective emphasizes individual freedom and responsibility.  Meaning isn't inherent; it's created through choices and actions.  We are \"condemned to be free\" and must create our own meaning.\n",
      "\n",
      "* **Absurdism:**  Recognizes the conflict between our desire for meaning and the meaningless universe.  We must embrace this absurdity and find joy in the present moment.\n",
      "\n",
      "* **Hedonism:**  Pleasure and happiness are the ultimate goals and the meaning of life.\n",
      "\n",
      "* **Purpose-driven life:**  Finding a purpose, often through contributing to something larger than oneself, gives life meaning.  This could be through religion, career, family, or social causes.\n",
      "\n",
      "* **Scientific perspective:**  Science generally doesn't address the meaning of life directly.  It focuses on understanding the natural world, including the origins and evolution of life.  From this perspective, biological purpose might be seen as survival and reproduction.\n",
      "\n",
      "* **Spiritual and religious perspectives:**  Many religions offer answers to the meaning of life, often involving serving a higher power, following divine commandments, and achieving enlightenment or salvation.\n",
      "\n",
      "Ultimately, the meaning of life is what you make it.  It's a question you answer for yourself through your experiences, values, and choices.  It can be a lifelong journey of exploration and discovery.\n"
     ]
    }
   ],
   "source": [
    "resp = llm.invoke(\"What is the meaning of life?\")\n",
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\" Anda adalah seorang guru matematika yang dapat menjelaskan suatu jawaban dari pertanyaan dengan\n",
    "                                          baik kepada anak sekolah dasar. Jawablah dengan tepat dan penyampaian yang sesuai untuk\n",
    "                                          anak sekolah dasar {pertanyaan}\"\"\")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baiklah, mari kita hitung bersama-sama langkah demi langkah!\n",
      "\n",
      "1. Pertama, kita mulai dengan mengalikan 5 dan 10. \n",
      "   Jadi, 5 * 10 = 50.\n",
      "\n",
      "2. Selanjutnya, kita bagi hasilnya dengan 2.\n",
      "   Jadi, 50 / 2 = 25.\n",
      "\n",
      "3. Sekarang, kita tambahkan 7 ke hasil yang kita dapatkan.\n",
      "   Jadi, 25 + 7 = 32.\n",
      "\n",
      "Jadi, jawaban dari 5 * 10 / 2 + 7 adalah 32! Bagus sekali, kita sudah menyelesaikannya!\n"
     ]
    }
   ],
   "source": [
    "resp = chain.invoke({\"pertanyaan\": \"Berapa jawaban dari 5*10/2 + 7\"})\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composed Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digunakan apabila ingin menggabungkan beberapa chain menjadi satu\n",
    "# misal di sini saya ingin membuat sebuah flow di mana\n",
    "# chain 1 : akan menggenerate list nama orang dan list aktivitas\n",
    "# chain 2 : akan mengatur orang mana yang akan mengerjakan aktivitas yang mana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = ChatPromptTemplate.from_template(\"\"\" buatkan 10 nama orang dengan nama yang khas indonesia, kemudian berikan 10 kegiatan yang dapat dilakukan \n",
    "                                          pada topik berikut {topik}\"\"\")\n",
    "\n",
    "chain_1 = prompt_1 | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = ChatPromptTemplate.from_template(\"\"\" Berdasarkan nama-nama orang tersebut aturlah siapa yang akan melakukan aktivitas apa pada topik berikut {list}\"\"\")\n",
    "\n",
    "chain_2 = {\"list\":chain_1} | prompt_2 | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Berikut adalah pembagian aktivitas olahraga berdasarkan nama-nama orang yang telah disebutkan. Saya akan mengaitkan setiap nama dengan kegiatan yang mungkin sesuai dengan karakter atau minat yang umum diasosiasikan dengan nama tersebut:\\n\\n1. **Rina Sari** - **Senam Aerobik**: Rina mungkin menyukai aktivitas yang energik dan sosial seperti senam aerobik.\\n2. **Budi Santoso** - **Bermain Sepak Bola**: Nama Budi sering diasosiasikan dengan olahraga tim, sehingga bermain sepak bola adalah pilihan yang tepat.\\n3. **Ayu Lestari** - **Yoga**: Ayu mungkin lebih suka aktivitas yang menenangkan dan fokus pada kesehatan mental, seperti yoga.\\n4. **Joko Prabowo** - **Lari Pagi**: Joko bisa jadi adalah tipe yang aktif dan menyukai kebugaran, sehingga lari pagi adalah pilihan yang baik.\\n5. **Siti Nurhaliza** - **Renang**: Siti mungkin menikmati relaksasi dan kebugaran yang ditawarkan oleh berenang.\\n6. **Andi Wijaya** - **Bersepeda**: Andi bisa jadi menyukai eksplorasi dan kebebasan, sehingga bersepeda adalah aktivitas yang cocok.\\n7. **Dewi Anggraini** - **Bermain Badminton**: Dewi mungkin menyukai olahraga yang cepat dan kompetitif, seperti badminton.\\n8. **Rizky Ramadhan** - **Panjat Tebing**: Rizky mungkin adalah tipe petualang yang suka tantangan, sehingga panjat tebing adalah pilihan yang tepat.\\n9. **Fitriani Putri** - **Olahraga Tim**: Fitriani mungkin senang bersosialisasi dan berkompetisi dalam tim, sehingga bergabung dengan olahraga tim adalah pilihan yang baik.\\n10. **Eko Susanto** - **Bersepeda Gunung**: Eko mungkin menyukai tantangan dan petualangan di alam, sehingga bersepeda gunung adalah aktivitas yang sesuai.\\n\\nSemoga pembagian ini bermanfaat dan sesuai dengan karakter yang diharapkan!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_2.invoke({\"topik\": \"olahraga\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misalkan kita memiliki biografi seorang tokoh yang terkenal, kemudian dari narasi biografi tersebut kita ingin mendapatkan informasi mengenai Nama,\n",
    "# Tanggal Lahir, Tempat Lahir, dan Pekerjaan dari tokoh tersebut serta pengalamanya. maka kita dapat melakukannya seperti berikut\n",
    "\n",
    "biography = \"\"\"\n",
    "LeBron James adalah seorang pemain bola basket profesional asal Amerika Serikat yang dianggap sebagai salah satu pemain terbaik dalam sejarah NBA. Ia lahir pada 30 Desember 1984, di Akron, Ohio. Sejak kecil, LeBron sudah menunjukkan bakat luar biasa dalam olahraga basket, yang membuatnya dikenal sebagai \"anak ajaib\" di dunia olahraga. Ia bersekolah di St. Vincent-St. Mary High School, di mana ia memimpin tim basket sekolah tersebut meraih kejuaraan negara bagian, sekaligus mendapatkan perhatian nasional sebagai pemain muda yang menjanjikan.\n",
    "\n",
    "Pada tahun 2003, LeBron James memasuki NBA sebagai pilihan pertama dalam draft, direkrut oleh Cleveland Cavaliers. Kariernya langsung bersinar, dan ia dinobatkan sebagai NBA Rookie of the Year pada musim pertamanya. Ia membawa Cavaliers ke beberapa penampilan playoff dan mencapai Final NBA pada tahun 2007, meskipun mereka kalah dari San Antonio Spurs.\n",
    "\n",
    "Pada 2010, LeBron membuat keputusan kontroversial dengan bergabung ke Miami Heat, di mana ia memenangkan dua gelar juara NBA pada tahun 2012 dan 2013. Setelah empat musim bersama Heat, ia kembali ke Cleveland Cavaliers pada 2014, dan pada 2016, LeBron berhasil membawa Cavaliers meraih gelar juara NBA pertama dalam sejarah klub, sekaligus memimpin comeback epik dari ketinggalan 1-3 melawan Golden State Warriors di Final NBA.\"\"\"\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Person(BaseModel):\n",
    "    name: str = Field(description=\"Nama orang yang dimaksud\")\n",
    "    tempat_tanggal_lahir: str = Field(description=\"Tempat dan tanggal lahir orang tersebut\")\n",
    "    pekerjaan: str = Field(description=\"Pekerjaan dari orang tersebut\")\n",
    "    pengalaman: str = Field(description=\"Pengalaman dari orang tersebut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LeBron James',\n",
       " 'tempat_tanggal_lahir': 'Akron, Ohio, 30 Desember 1984',\n",
       " 'pekerjaan': 'Pemain Bola Basket Profesional',\n",
       " 'pengalaman': 'Memulai karier di NBA pada tahun 2003 dengan Cleveland Cavaliers, dinobatkan sebagai NBA Rookie of the Year, memenangkan dua gelar juara NBA bersama Miami Heat pada tahun 2012 dan 2013, serta membawa Cleveland Cavaliers meraih gelar juara NBA pertama pada tahun 2016.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Person)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Buatkan berdasarkan biografi berikut.\\n{biography}\\n{format_instructions}\\n\",\n",
    "    input_variables=[\"biography\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "chain.invoke({\"biography\": biography})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from typing import List\n",
    "\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import BaseMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.runnables import (\n",
    "    RunnableLambda,\n",
    "    ConfigurableFieldSpec,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from langchain_community.chat_models import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
    "    \"\"\"In memory implementation of chat message history.\"\"\"\n",
    "\n",
    "    messages: List[BaseMessage] = Field(default_factory=list)\n",
    "\n",
    "    def add_messages(self, messages: List[BaseMessage]) -> None:\n",
    "        \"\"\"Add a list of messages to the store\"\"\"\n",
    "        self.messages.extend(messages)\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.messages = []\n",
    "\n",
    "# Here we use a global variable to store the chat message history.\n",
    "# This will make it easier to inspect it to see the underlying results.\n",
    "store = {}\n",
    "\n",
    "def get_by_session_id(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you are asistant for a physics teacher\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Gravity is a fundamental force of nature that attracts two bodies with mass toward each other. It is responsible for a variety of phenomena, including the falling of objects to the ground, the orbits of planets around stars, and the formation of galaxies.\\n\\nIn classical physics, gravity is described by Isaac Newton's law of universal gravitation, which states that every point mass attracts every other point mass with a force that is directly proportional to the product of their masses and inversely proportional to the square of the distance between their centers. The formula for this force \\\\( F \\\\) is given by:\\n\\n\\\\[\\nF = G \\\\frac{m_1 m_2}{r^2}\\n\\\\]\\n\\nwhere:\\n- \\\\( F \\\\) is the gravitational force,\\n- \\\\( G \\\\) is the gravitational constant (\\\\(6.674 \\\\times 10^{-11} \\\\, \\\\text{N m}^2/\\\\text{kg}^2\\\\)),\\n- \\\\( m_1 \\\\) and \\\\( m_2 \\\\) are the masses of the two objects,\\n- \\\\( r \\\\) is the distance between the centers of the two masses.\\n\\nIn modern physics, gravity is described by Albert Einstein's general theory of relativity, which posits that gravity is not just a force but a curvature of spacetime caused by mass. According to this theory, massive objects like planets and stars warp the fabric of spacetime around them, and this curvature affects the motion of other objects, causing them to follow curved paths.\\n\\nOverall, gravity is a key force that governs the structure and behavior of the universe on both small and large scales.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_by_session_id,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "chain_with_history.invoke(\n",
    "    {\"question\": \"What is gravity?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user_abdul\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked, \"What is gravity?\" If you have any specific aspects of gravity you\\'d like to know more about or if you have further questions, feel free to ask!'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke(\n",
    "    {\"question\": \"What i asked before?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user_abdul\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Google Search Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "retriever = TavilySearchResults(\n",
    "    max_results=5,\n",
    "    search_depth=\"advanced\",\n",
    "    include_answer=True,\n",
    "    include_raw_content=True,\n",
    "    # include_images=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatif untuk tavily search\n",
    "# from langchain_community.retrievers import TavilySearchAPIRetriever\n",
    "# retriever = TavilySearchAPIRetriever(\n",
    "#     k=3,\n",
    "#     search_depth=\"advanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the question based only on the context provided.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc[\"content\"] for doc in docs)\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"query\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Apa hal kontroversial yang dilakukan wasit pada pertandingan bahrain vs indonesia?\"\n",
    "chain.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine memory and retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not a good implementation better using agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the question based only on the context provided. \\n Context: {context}\"),\n",
    "    (\"human\", \"{query}\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "   \n",
    "])\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc[\"content\"] for doc in docs)\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"query\": RunnablePassthrough(),\"history\":itemgetter(\"history\")}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_by_session_id,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hal kontroversial yang dilakukan wasit Ahmed Al Kaf pada pertandingan Bahrain vs Indonesia adalah memberikan tambahan waktu yang tidak sesuai dengan aturan lapangan. Wasit membiarkan Timnas Bahrain mencetak gol pada menit 90+9, padahal tambahan waktu yang seharusnya diberikan hanya enam menit.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke({\"query\":\"Apa hal kontroversial yang dilakukan wasit pada pertandingan bahrain vs indonesia?\"},config={\"configurable\": {\"session_id\": \"user_rizki\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reaksi dari suporter Timnas Indonesia setelah pertandingan melawan Bahrain adalah kekecewaan, terutama terkait dengan keputusan wasit yang dianggap mencurangi tim. Kekecewaan ini juga mendapatkan dukungan dari suporter Jepang, yang menunjukkan bahwa peristiwa tersebut terdengar hingga ke berbagai negara di penjuru dunia.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke({\"query\":\"Apa rekasi dari supporter timnas indonesia ?\"},config={\"configurable\": {\"session_id\": \"user_rizki\"}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
